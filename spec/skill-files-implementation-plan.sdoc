# Lexica — Implementation Plan @lexica-impl-plan
{
    # Meta @meta
    {
        author: Michael + Claude
        date: 2026-02-19
        status: Draft — for review
        depends-on: skill-files-design.sdoc
    }

    # Overview @overview
    {
        This document plans the concrete changes needed in the sdoc repo to implement
        Lexica as described in @lexica-design. The goal is to go from what exists today
        (a parser, a VS Code extension, and a design doc) to a working system where
        agents can discover, navigate, and load knowledge files progressively.

        The plan is ordered in phases. Each phase delivers usable value and can be
        shipped independently. Later phases build on earlier ones but are not blocked
        by being designed up front — we expect the design to evolve as we learn from
        real usage.
    }

    # What Exists Today @current-state
    {
        {[.]
            - **Parser** (\`src/sdoc.js\`) — complete, robust, ~1800 lines. Parses all
              SDOC syntax into a clean AST with node types: scope, paragraph, list,
              table, code, blockquote, hr. Every node tracks lineStart/lineEnd.
            - **Meta extraction** — \`extractMeta(nodes)\` finds the \@meta scope and
              pulls out style, header, footer, and key:value pairs.
            - **Formatter** — \`formatSdoc(text, indentStr)\` reindents based on brace
              depth.
            - **HTML renderer** — full document and fragment rendering with CSS,
              collapsible scopes, click-to-navigate, inline editing.
            - **VS Code extension** — preview, export, browser view, document server,
              formatting, config cascading (\`sdoc.config.json\`).
            - **Document server** — HTTP server that collects all \`.sdoc\` files in a
              tree, serves a manifest and individual document content.
            - **AI skill reference** — registers an \`sdoc_reference\` language model
              tool that serves the full SDOC_GUIDE.md to agents. This is the only
              agent-facing capability today.
            - **Tests** — custom test runner, ~300+ tests covering parser functionality.
        }

        What does NOT exist:

        {[.]
            - No slug generation from heading text
            - No section listing (get all headings with IDs from a document)
            - No section extraction by ID (get one section's content)
            - No \@about extraction or generation
            - No knowledge file discovery (walking \`skills/\` and \`docs/\` directories)
            - No scope-aware resolution (proximity ranking)
            - No MCP server
            - No manifest generation
            - No cross-file reference resolution
        }
    }

    # Phase 1: Parser Extensions @phase-1
    {
        Add utility functions to \`src/sdoc.js\` that the MCP server and tooling will
        need. These are pure functions operating on the existing AST — no new
        dependencies, no VS Code coupling.

        # 1a. Slug Generation @slugify
        {
            A function that converts heading text to a derived section ID.

            ```javascript
            slugify("Smart Pointers")    // => "smart-pointers"
            slugify("RAII Pattern")      // => "raii-pattern"
            slugify("C++ Memory Mgmt")   // => "c-memory-mgmt"
            ```

            Rules: lowercase, replace non-alphanumeric runs with a single hyphen, trim
            leading/trailing hyphens. Strip inline formatting markers (\`*\`, \`~\`, etc.)
            before slugifying.
        }

        # 1b. Section Listing @list-sections
        {
            Given a parsed AST, return an array of section descriptors — one per
            top-level content scope (excluding \@meta and \@about).

            ```javascript
            listSections(nodes)
            // => [
            //   { id: "raii", title: "RAII Pattern", derivedId: "raii-pattern",
            //     preview: "Resource Acquisition Is Initialization..." },
            //   { id: null, title: "Smart Pointers", derivedId: "smart-pointers",
            //     preview: "Modern C++ provides three smart pointer..." },
            // ]
            ```

            Each entry includes:
            {[.]
                - \`id\` — explicit \@id if present, null otherwise
                - \`derivedId\` — slugified heading text (always present)
                - \`title\` — raw heading text
                - \`preview\` — first ~100 chars of the section's first paragraph
            }

            The effective ID for extraction is \`id ?? derivedId\`.
        }

        # 1c. Section Extraction @extract-section
        {
            Given a parsed AST and a section ID (explicit or derived), return that
            section's AST subtree rendered to plain text or HTML.

            ```javascript
            extractSection(nodes, "smart-pointers")
            // => { title: "Smart Pointers", content: "Modern C++ provides..." }
            ```

            Matching: first check explicit \@ids, then check derived IDs. Case-insensitive
            matching on derived IDs.
        }

        # 1d. About Extraction @extract-about
        {
            Extract the \@about section's text content from a parsed AST. Returns null
            if no \@about section exists.

            ```javascript
            extractAbout(nodes)
            // => "Memory management patterns in modern C++. Covers RAII..."
            ```

            This is similar to \`extractMeta\` but for the \@about scope specifically.
        }

        # 1e. Enhanced Meta Extraction @enhanced-meta
        {
            Extend the existing \`extractMeta\` to also pull \`uuid\`, \`type\`, and \`tags\`
            from key:value pairs in \@meta.

            ```javascript
            extractMeta(nodes)
            // => { uuid: "550e8400-...", type: "skill", tags: ["cpp", "memory"],
            //      style: null, header: null, footer: null, ... }
            ```
        }

        # Phase 1 Deliverables @phase-1-deliverables
        {
            {[.]
                - 5 new exported functions from \`src/sdoc.js\`
                - Tests for each function
                - No changes to the VS Code extension
                - No new files or dependencies
            }
        }
    }

    # Phase 2: Knowledge Discovery @phase-2
    {
        Build the filesystem walking logic that finds knowledge files. This is a
        standalone module — used by the MCP server, the document server, and
        potentially CLI tooling.

        # 2a. Directory Walker @directory-walker
        {
            Given a working directory, walk upward collecting all files in \`skills/\`
            and \`docs/\` directories at each level up to the repo root, plus
            \`~/skills/\` for global skills.

            Returns an array of knowledge descriptors, ordered by proximity (closest
            first):

            ```javascript
            discoverKnowledge("/repo/src/auth/")
            // => [
            //   { path: "/repo/src/auth/skills/oauth.sdoc", scope: "src/auth",
            //     dirType: "skills", ... },
            //   { path: "/repo/src/auth/docs/auth-api.sdoc", scope: "src/auth",
            //     dirType: "docs", ... },
            //   { path: "/repo/skills/conventions.sdoc", scope: "repo",
            //     dirType: "skills", ... },
            //   { path: "/repo/docs/architecture.sdoc", scope: "repo",
            //     dirType: "docs", ... },
            //   { path: "~/skills/cpp-memory.sdoc", scope: "global",
            //     dirType: "skills", ... },
            // ]
            ```

            Each descriptor includes:
            {[.]
                - \`path\` — absolute path to the file
                - \`scope\` — "global", "repo", or relative directory path
                - \`dirType\` — "skills" or "docs"
                - \`uuid\` — from \@meta (if present, SDOC files only)
                - \`about\` — from \@about section (if present, SDOC files only)
                - \`title\` — root heading text (or filename for non-SDOC files)
            }
        }

        # 2b. Repo Root Detection @repo-root
        {
            Walk upward from working directory looking for \`.git/\`. This determines
            where the upward walk stops (before jumping to global).

            This is straightforward — just check for \`.git\` directory at each level.
        }

        # 2c. Global Skills Directory @global-skills
        {
            Check \`~/skills/\` for global skill files. These are appended to the
            discovery results with \`scope: "global"\`.

            Open question: should the global directory location be configurable via an
            environment variable (\`LEXICA_SKILLS_HOME\`) or a config file? For now,
            hardcode \`~/skills/\` and revisit if needed.
        }

        # Phase 2 Deliverables @phase-2-deliverables
        {
            {[.]
                - New module: \`src/discovery.js\` (or added to \`sdoc.js\`)
                - \`discoverKnowledge(workingDir)\` function
                - Tests with fixture directories
                - No VS Code dependency — pure Node.js
            }
        }
    }

    # Phase 3: MCP Server @phase-3
    {
        A standalone MCP server that wraps the parser extensions and discovery logic
        as tools. This is the primary interface for AI agents.

        # Server Setup @mcp-server-setup
        {
            The MCP server runs as a separate process, not inside the VS Code extension.
            This means agents that are not using VS Code (CLI agents, CI pipelines, etc.)
            can still use it.

            Implementation options:
            {[.]
                - **Standalone Node.js process** — started via \`npx sdoc-mcp\` or similar.
                  Communicates via stdio (standard MCP transport).
                - **Integrated into the document server** — extend the existing HTTP server
                  with MCP endpoints. Reuses the server infrastructure but couples to VS Code.
            }

            Recommendation: standalone process. Keep the MCP server independent of the
            VS Code extension so it works in any agent environment.
        }

        # MCP Tools @mcp-tools
        {
            Four tools as described in the design doc:

            # list_knowledge @tool-list
            {
                Input: working directory (optional, defaults to repo root)
                Returns: array of { uuid, path, scope, dirType, title, about } for all
                visible knowledge

                Implementation: call \`discoverKnowledge()\`, parse each SDOC file, extract
                meta and about. Return filename and first lines for non-SDOC files. Cache
                parsed results.
            }

            # search @tool-search
            {
                Input: query string + working directory (optional)
                Returns: ranked subset of visible knowledge matching the query

                Ranking: combine text similarity (query vs title + about) with proximity
                (closer knowledge ranks higher). For v1, a simple keyword match on title
                and about text is sufficient — no need for embeddings.
            }

            # get_sections @tool-get-sections
            {
                Input: file path (or uuid)
                Returns: array of { id, derivedId, title, preview } for all content sections

                Implementation: parse the file, call \`listSections()\`. For Markdown files,
                use heading-based best-effort parsing.
            }

            # get_section @tool-get-section
            {
                Input: file path (or uuid) + section ID
                Returns: full text content of that section

                Implementation: parse the file, call \`extractSection()\`.
            }
        }

        # Caching @mcp-caching
        {
            The MCP server should cache parsed ASTs and discovery results. Knowledge files
            change infrequently — reparsing on every tool call is wasteful.

            Simple approach: cache keyed by file path + mtime. Invalidate when the file's
            modification time changes. No file watchers needed for v1 — just check mtime
            on each access.
        }

        # Phase 3 Deliverables @phase-3-deliverables
        {
            {[.]
                - New file: \`src/mcp-server.js\` (or \`src/mcp/\` directory)
                - MCP server exposing 4 tools via stdio transport
                - Runnable via \`node src/mcp-server.js\` or a bin entry in package.json
                - Tests for each tool
                - Documentation for configuring the MCP server in Claude Code, Cursor, etc.
            }
        }
    }

    # Phase 4: VS Code Integration @phase-4
    {
        Extend the VS Code extension to support knowledge file authoring workflows.

        # 4a. New Knowledge File Command @new-file-command
        {
            A command ("SDOC: New Knowledge File") that:

            {[#]
                1. Prompts for a title and whether this is a skill or doc
                2. Creates the file in the nearest \`skills/\` or \`docs/\` directory
                   (creating it if needed)
                3. Generates a UUID
                4. Writes a skeleton with \@meta (uuid), empty \@about, and one empty
                   content section
            }
        }

        # 4b. Generate About Command @generate-about-command
        {
            A command ("SDOC: Generate About") that reads the current file's content
            sections and generates an \@about paragraph using the VS Code language model
            API (same API used by the existing \`sdoc_reference\` tool).

            Inserts or replaces the \@about section in the file. The author reviews
            the result.
        }

        # 4c. Update the AI Skill Reference @update-skill-reference
        {
            The existing \`sdoc_reference\` language model tool dumps the entire
            SDOC_GUIDE.md (~1100 lines) into agent context. This needs to be smarter.

            Options:
            {[.]
                - **Add reading guidance preamble** — a short paragraph at the top of the
                  guide that tells agents: "The Quick Reference section is sufficient for
                  writing SDOC. Only read the Full Specification for edge cases. Common
                  Mistakes is essential reading for any agent generating SDOC."
                - **Split into progressive sections** — serve the quick reference by default,
                  offer the full spec as a follow-up tool call.
                - **Convert to an SDOC skill file** — make SDOC_GUIDE.md itself an SDOC
                  knowledge file with \@about, and serve it through the MCP server's
                  progressive disclosure tools.
            }

            The first option (reading guidance preamble) is the quick win. The third
            option (eat our own dogfood) is the right long-term answer.
        }

        # Phase 4 Deliverables @phase-4-deliverables
        {
            {[.]
                - Two new VS Code commands
                - Updated \`sdoc_reference\` tool with reading guidance (at minimum)
                - Bump extension version
            }
        }
    }

    # Phase 5: Automation @phase-5
    {
        Build the tooling that generates metadata automatically, so authors never
        have to think about it.

        # 5a. Pre-Commit Hook @pre-commit-hook
        {
            A script (invokable via husky, lefthook, or standalone) that runs on
            staged \`.sdoc\` files in \`skills/\` and \`docs/\` directories:

            {[#]
                1. If no UUID in \@meta, generate one and inject it
                2. If no \@about section, generate one from content (requires an AI call
                   — either local model or API)
                3. Stage the modified file
            }

            The UUID generation is deterministic and free. The \@about generation
            requires an AI model — this is the main design question. Options:

            {[.]
                - **API call** (Anthropic, OpenAI) — reliable but requires credentials
                  in the dev environment and costs money per commit
                - **Local model** — free and private but requires setup and may produce
                  lower-quality summaries
                - **Defer to CI** — skip \@about in the hook, let CI handle it at merge
                  time. Simpler hook but the PR diff does not show the \@about until CI
                  runs.
            }

            Recommendation: generate UUID in the hook (free, instant). Defer \@about
            to a VS Code command or CI. The hook should be lightweight and not require
            network access.
        }

        # 5b. Manifest Generator @manifest-generator
        {
            A script that walks the tree, collects all knowledge files from \`skills/\`
            and \`docs/\` directories, and emits a JSON manifest.

            ```bash
            node tools/generate-manifest.js --root /path/to/repo
            ```

            Output:
            ```json
            {
                "generated": "2026-02-19T...",
                "knowledge": [
                    {
                        "uuid": "550e8400-...",
                        "path": "skills/conventions.sdoc",
                        "scope": "repo",
                        "dirType": "skills",
                        "title": "Coding Conventions",
                        "about": "Project coding conventions covering...",
                        "sections": ["naming", "error-handling", "testing"]
                    },
                    {
                        "uuid": "7a3b1c00-...",
                        "path": "docs/architecture.sdoc",
                        "scope": "repo",
                        "dirType": "docs",
                        "title": "Project Architecture",
                        "about": "System architecture overview...",
                        "sections": ["overview", "components", "data-flow"]
                    }
                ]
            }
            ```

            The MCP server can use this manifest for fast startup instead of
            parsing every file on launch. But the manifest is optional — the
            server should work without it by doing live discovery.
        }

        # Phase 5 Deliverables @phase-5-deliverables
        {
            {[.]
                - Pre-commit hook script (UUID generation only for v1)
                - Manifest generator script
                - Documentation for setting up hooks
            }
        }
    }

    # What We Are NOT Building Yet @not-building
    {
        These are in the design doc but deferred until we have real usage to guide
        the design:

        {[.]
            - **Generative merge gate** — CI pipeline that generates \@about and tags
              at merge time. Needs a CI environment and API credentials. Build when
              a team actually wants it.
            - **Cross-file reference resolution** — syntax and tooling for referencing
              sections across knowledge files. The \@id system works within a file;
              cross-file needs more design. Build when someone has enough files to need it.
            - **Tag taxonomy** — canonical tag vocabulary and AI-constrained tag generation.
              Build when there are enough knowledge files to need categorisation.
            - **Shared knowledge submodule template** — a starter shared repo that
              teams can fork. Build when we have enough example files to populate it.
            - **Markdown section parser** — best-effort heading-based section extraction
              for Markdown files in \`skills/\` and \`docs/\`. Discovery works immediately
              (any file is found); progressive disclosure for Markdown is a later
              enhancement.
        }
    }

    # Sequencing and Dependencies @sequencing
    {
        {[table]
            Phase | Depends on | Estimated scope | Ships value
            1. Parser extensions | Nothing | ~200 lines + tests | Foundation only
            2. Knowledge discovery | Phase 1 (meta extraction) | ~150 lines + tests | Foundation only
            3. MCP server | Phases 1 + 2 | ~300 lines + tests | Agents can navigate knowledge
            4. VS Code integration | Phase 1 (for about generation) | ~200 lines | Authors can create knowledge files
            5. Automation | Phases 1 + 2 | ~100 lines + scripts | Zero-friction authoring
        }

        Phases 1 and 2 are foundational but not user-visible. Phase 3 is where agents
        start getting value. Phase 4 is where authors start getting value. Phase 5 is
        polish.

        A pragmatic order: 1 → 2 → 3 → 4 → 5, with the caveat that the quick win
        from @update-skill-reference (adding reading guidance to the existing skill
        reference) can happen immediately, before any of this, and should.
    }

    # Open Questions for This Plan @plan-questions
    {
        {[.]
            - Should the MCP server be a separate npm package or part of this repo?
              If separate, it can be installed independently of the VS Code extension.
              If bundled, it ships with the extension but requires VS Code to be present.
            - Where does the MCP server live in the file structure? \`src/mcp-server.js\`
              as a single file, or \`src/mcp/\` as a directory with tool handlers split out?
            - Should \`discoverKnowledge()\` go into \`src/sdoc.js\` (keeping the monolith) or
              a new \`src/discovery.js\` (starting to modularise)? The parser is already
              ~1800 lines.
            - For the \`search\` MCP tool, is keyword matching on title + about sufficient
              for v1, or do we need something smarter from the start?
            - How do we test the MCP server? Mock filesystem? Real fixture directories?
              Integration tests with an actual MCP client?
            - Does \`docs/\` at the repo root need a convention to avoid collision with
              projects that use \`docs/\` for GitHub Pages or user-facing documentation?
        }
    }
}
